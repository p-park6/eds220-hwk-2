{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "## General instructions\n",
    "\n",
    "First, update the following cell to have a link to your Homework 2 GitHub repository\n",
    "\n",
    "**UPDATE THIS LINK**\n",
    "https://github.com/p-park6/eds220-hwk-2\n",
    "\n",
    "Add comments for all your code and commit as needed. Err on the side of commenting and commiting too much for now.\n",
    "\n",
    "\n",
    "## About the data\n",
    "\n",
    "In this task you will use [Air Quality Index (AQI)](https://www.airnow.gov/aqi/aqi-basics/) data from the [US Environmental Protection Agency](https://www.epa.gov) to visualize the impact on the AQI of the 2017 [Thomas Fire](https://en.wikipedia.org/wiki/Thomas_Fire) in Santa Barbara County. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL CODE\n",
    "\n",
    "You will use the next cell at the end of the task. Leave it blank for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===== FINAL CODE ====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "1. Go to [EPA's website on Air Quality Data Collected at Outdoor Monitors Across the US](https://www.epa.gov/outdoor-air-quality-data). \n",
    "2. Under \"Donwload Data\" click on \"Pre-generated Data Files\"\n",
    "3. Click on \"Tables of Daily AQI\"\n",
    "4. Copy the URL to the 2017 Daily AQI **by County** zip file `daily_aqi_by_county_2017.zip`\n",
    "5. In the next code cell read in the data from the URL using the `pd.read_csv` function and store it as `aqi_17`. \n",
    "6. In the same cell, read in the data for the 2018 Daily AQI by County zip file and store it as `aqi_18`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in daily AQI 2017 zip file from url\n",
    "aqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\")\n",
    "\n",
    "# read in daily AQI 2018 zip file from url\n",
    "aqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 \n",
    "(a) and (b) Use the next two cells to look at the head of both data frames.\n",
    "\n",
    "(c) Use this cell to make some other preliminary data exploration of your choosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a)\n",
    "#look at the first 5 observations of aqi 17\n",
    "aqi_17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b)\n",
    "#look at the first 5 observations of aqi 18\n",
    "aqi_18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (c) \n",
    "#look at the last 5 observations of aqi 17\n",
    "print(aqi_17.tail())\n",
    "\n",
    "#look at the last 5 observations of aqi 18\n",
    "print(aqi_18.tail())\n",
    "\n",
    "#look at unique columns in aqi 17\n",
    "print(aqi_17.columns)\n",
    "\n",
    "#look at unique columns in aqi 18\n",
    "print(aqi_18.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\n",
    "We currently have two separate dataframes. For this exercise we will need to \"glue\" them one on top of the other. The pandas function `pd.concat()` can achieve this. \n",
    "\n",
    "Pass `[aqi_17, aqi_18]` as the input of `pd.concat()` and store the output as  `aqi`.  \n",
    "In the next line run `aqi`.\n",
    "\n",
    "ðŸ‘€ NOTE: When we concatenate like this, without any extra parameters for `pd.concat()` the indices for the two dataframes are just \"glued together\", the index of the resulting dataframe is not updated to start from 0. Notice the index of `aqi` ends in 327536 while it has 654338 rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the two datasets together\n",
    "aqi = pd.concat([aqi_17, aqi_18])\n",
    "aqi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\n",
    "\n",
    "Run the follwoing cell and read the comments to understand how the column names are being updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial column names: notice caps and spaces (difficult to work with!)\n",
    "print(aqi.columns, '\\n')\n",
    "\n",
    "# re-assign the column names - .str.lower() makes them lower case\n",
    "aqi.columns = aqi.columns.str.lower()\n",
    "print(aqi.columns, '\\n')\n",
    "\n",
    "#  re-assign the column names again - .str.replace(' ','_') replaces the space for _\n",
    "aqi.columns = aqi.columns.str.replace(' ','_')\n",
    "print(aqi.columns)\n",
    "\n",
    "# as a \"one liner\" you could achieve this column name cleaning like this:\n",
    "# aqi.columns = aqi.columns.str.lower().str.replace(' ','_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 \n",
    "In the next cell:\n",
    "- Select only data from `Santa Barbara` county and store in a new variable `aqi_sb`.\n",
    "- Remove the `state_name`, `county_name`, `state_code` and `county_code` columns from `aqi_sb`. \n",
    "- Use the `dtypes` attribute to check the data types of the columns. What do you notice for the date column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter for observations that are in Santa Barbara County\n",
    "aqi_sb = aqi[aqi['county_name'] == 'Santa Barbara']\n",
    "\n",
    "#print aqi_sb dataframe\n",
    "print(aqi_sb)\n",
    "\n",
    "#remove \n",
    "aqi_sb = aqi_sb.drop(columns=['state_name','county_name','state_code','county_code'])\n",
    "\n",
    "#use column function on aqi_sb dataframe to see if columns were removed\n",
    "print(aqi_sb.columns)\n",
    "\n",
    "#use dtypes to check for data types\n",
    "aqi_sb.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: I notice that the date type is as an object. I would expect it to be in a datetime type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6\n",
    "In the next cell:\n",
    "1. Update the date column of `aqi_sb` to be a datetime object.\n",
    "2. Update the index of `aqi_sb` to be the date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                         datetime64[ns]\n",
      "aqi                                   int64\n",
      "category                             object\n",
      "defining_parameter                   object\n",
      "defining_site                        object\n",
      "number_of_sites_reporting             int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aqi</th>\n",
       "      <th>category</th>\n",
       "      <th>defining_parameter</th>\n",
       "      <th>defining_site</th>\n",
       "      <th>number_of_sites_reporting</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>39</td>\n",
       "      <td>Good</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>06-083-4003</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>36</td>\n",
       "      <td>Good</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>06-083-4003</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>71</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>PM10</td>\n",
       "      <td>06-083-4003</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>34</td>\n",
       "      <td>Good</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>06-083-4003</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>37</td>\n",
       "      <td>Good</td>\n",
       "      <td>Ozone</td>\n",
       "      <td>06-083-4003</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            aqi  category defining_parameter defining_site  \\\n",
       "date                                                         \n",
       "2017-01-01   39      Good              Ozone   06-083-4003   \n",
       "2017-01-02   36      Good              Ozone   06-083-4003   \n",
       "2017-01-03   71  Moderate               PM10   06-083-4003   \n",
       "2017-01-04   34      Good              Ozone   06-083-4003   \n",
       "2017-01-05   37      Good              Ozone   06-083-4003   \n",
       "\n",
       "            number_of_sites_reporting  \n",
       "date                                   \n",
       "2017-01-01                         12  \n",
       "2017-01-02                         11  \n",
       "2017-01-03                         12  \n",
       "2017-01-04                         13  \n",
       "2017-01-05                         12  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change date type to be in datetime object (can be ran only one time)\n",
    "aqi_sb.date = pd.to_datetime(aqi_sb.date)\n",
    "#print out the column types to see if date type was changed\n",
    "print(aqi_sb.dtypes)\n",
    "\n",
    "#change index to be set to date\n",
    "aqi_sb = aqi_sb.set_index('date')\n",
    "#look at observations to see if the index has changed to date\n",
    "aqi_sb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7\n",
    "In the next cell, check that you've updated the index by accessing the index of `aqi_sb`  by running `aqi_sb.index`. Add in a comment what is the data type (dtype) of the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2017-01-01', '2017-01-02', '2017-01-03', '2017-01-04',\n",
       "               '2017-01-05', '2017-01-06', '2017-01-07', '2017-01-08',\n",
       "               '2017-01-09', '2017-01-10',\n",
       "               ...\n",
       "               '2018-12-22', '2018-12-23', '2018-12-24', '2018-12-25',\n",
       "               '2018-12-26', '2018-12-27', '2018-12-28', '2018-12-29',\n",
       "               '2018-12-30', '2018-12-31'],\n",
       "              dtype='datetime64[ns]', name='date', length=730, freq=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to see if the index has been updated to date\n",
    "aqi_sb.index\n",
    "\n",
    "#comment: the dtype is datetime64[ns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8\n",
    "Run the next cell and read through the comments. They will explain how to calculate an average over a [rolling window](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.rolling.html).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2017-01-01    39.000000\n",
       "2017-01-02    37.500000\n",
       "2017-01-03    48.666667\n",
       "2017-01-04    45.000000\n",
       "2017-01-05    43.400000\n",
       "                ...    \n",
       "2018-12-27    38.600000\n",
       "2018-12-28    38.600000\n",
       "2018-12-29    38.200000\n",
       "2018-12-30    37.800000\n",
       "2018-12-31    38.400000\n",
       "Name: aqi, Length: 730, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rolling() is a method for pandas.series that provides rolling window calculations\n",
    "# the parameter '5D' indicates we want the window to be 5 days\n",
    "# This is a lazy method (think groupby), we need to specify what we want to calculate over each window\n",
    "# here we add the aggregator function mean()\n",
    "# this indicates we want the mean over each window\n",
    "# and we get a pd.Series as ouput\n",
    "aqi_sb.aqi.rolling('5D').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 \n",
    "\n",
    "Without creating any new variables, add the mean of the AQI over a 5-day rolling window as a new column named 'five_day_average' to the `aqi_sb` dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['aqi', 'category', 'defining_parameter', 'defining_site',\n",
       "       'number_of_sites_reporting', 'five_day_average'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new column that is the 5 day rolling average mean\n",
    "aqi_sb['five_day_average'] = aqi_sb.aqi.rolling('5D').mean()\n",
    "#print the column names to see if the new column has been created\n",
    "aqi_sb.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10\n",
    "Make a line plot showing both the daily AQI and the 5-day average (5-day average on top of the AQI). Update the title and colors of the graph. Can you see the AQI going up during the Thomas Fire in December 2017?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve exercise here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11\n",
    "\n",
    "Collect all the relevant code into the first blank cell of the notebook titled \"FINAL CODE\". This single cell will have the end-to-end workflow: from importing libraries and loading the data, to producing the graph. The *only* ouput of this cell should be the graph you produced in the previous exercise. For each line, add a single comment explaining what the code does."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "096ff075efa46b48fdc6093cb088d328f1206dfedfbeb0f42cf6b14174f51118"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
